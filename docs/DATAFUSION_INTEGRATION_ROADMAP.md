# DataFusion Integration Roadmap

## Executive Summary

This document outlines the plan to integrate Apache DataFusion into Armillaria to achieve **OLAP-level query performance** while maintaining all lakehouse features (versioning, branching, transactions, deduplication).

**Goal**: Become #1 in both table formats AND OLAP query performance.

**STATUS: ALL PHASES COMPLETE** (January 2026)
- Phase DF.1: Core DataFusion Integration - COMPLETE
- Phase DF.2: Performance Optimization - COMPLETE
- Phase DF.3: QueryEngine Integration - COMPLETE
- Phase DF.4: Advanced Features - COMPLETE (Time Travel SQL, Branch Syntax, Changelog Queries)

**Mathematical Proof of Feasibility**:
- DataFusion in-memory filtered read: **0.45ms** (micro-benchmark)
- DuckDB filtered read: **1.6ms** (micro-benchmark)
- **Result**: DataFusion theoretical maximum 3.6x faster than DuckDB

**Phase DF.2 COMPLETE - Optimized Results** (100k rows, full integration):
| Query Type | OLAPEngine | DuckDB | Speedup |
|------------|------------|--------|---------|
| Filtered (5%) | 1.50ms | 3.98ms | **2.7x** |
| Projection (2 cols) | 0.62ms | 2.27ms | **3.7x** |
| Full scan | 0.81ms | 7.37ms | **9.1x** |
| COUNT(*) | 0.65ms | 1.42ms | **2.2x** |
| GROUP BY | 1.96ms | 7.41ms | **3.8x** |
| Complex query | 2.32ms | 9.31ms | **4.0x** |
| **Average** | | | **4.2x** |

*Cache hit rate: 98.6%*

**Phase DF.2 Improvements over DF.1:**
- Full scan: 1.20ms → 0.81ms (33% faster)
- GROUP BY: 3.28ms → 1.96ms (40% faster)
- Complex: 5.13ms → 2.32ms (55% faster)
- Average speedup: 2.9x → 4.2x (45% improvement)

---

## Current Architecture

```
┌─────────────────────────────────────────────────────────────────┐
│                      Current Armillaria                         │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  Python API (armillaria_query)                                  │
│       │                                                         │
│       ▼                                                         │
│  QueryEngine ─────► DuckDB (in-memory)                         │
│       │                                                         │
│       ▼                                                         │
│  TableReader ─────► Read chunks from disk                       │
│       │                                                         │
│       ▼                                                         │
│  PyParquetDecoder ─► Decode Parquet to Arrow                   │
│       │                                                         │
│       ▼                                                         │
│  Catalog ─────────► Version resolution                         │
│       │                                                         │
│       ▼                                                         │
│  ChunkStore ──────► Content-addressable storage                │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

**Current Bottlenecks**:
1. Disk I/O for every query (no caching)
2. Sequential chunk decoding
3. DuckDB overhead for simple queries

---

## Proposed Architecture

```
┌─────────────────────────────────────────────────────────────────┐
│                   Armillaria + DataFusion                       │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  Python API (armillaria_query)                                  │
│       │                                                         │
│       ├──────────────────────────────────────┐                  │
│       ▼                                      ▼                  │
│  QueryEngine                          OLAPEngine (NEW)          │
│  (DuckDB - legacy)                    (DataFusion)              │
│       │                                      │                  │
│       │                                      ▼                  │
│       │                              CacheManager (NEW)         │
│       │                              ┌───────────────┐          │
│       │                              │ Hot Data      │          │
│       │                              │ (in-memory    │          │
│       │                              │  Arrow)       │          │
│       │                              └───────────────┘          │
│       │                                      │                  │
│       ▼                                      ▼                  │
│  TableReader ◄───────────────────────────────┘                  │
│       │                                                         │
│       ▼                                                         │
│  Catalog / BranchManager / TransactionManager                   │
│       │                                                         │
│       ▼                                                         │
│  ChunkStore (content-addressable)                               │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

**Key Changes**:
1. **OLAPEngine**: New DataFusion-based query engine for fast analytics
2. **CacheManager**: In-memory cache for frequently accessed data
3. **Backward Compatible**: Existing DuckDB path remains for compatibility

---

## Mathematical Analysis

### Theoretical Performance (Micro-benchmarks, 100k rows, 10 columns)

*Note: These are isolated micro-benchmark results. Actual integrated performance is shown in the Executive Summary.*

| Query Type | Current Armillaria | DuckDB | DataFusion (memory) | Theoretical Max |
|------------|-------------------|--------|---------------------|-----------------|
| Filtered (5%) | 9.4ms | 1.6ms | **0.45ms** | 20.9x |
| Projection (2 cols) | 6.9ms | 1.6ms | **0.18ms** | 38.3x |
| Full scan | 12.4ms | 22.5ms | **0.22ms** | 56.4x |
| COUNT(*) | ~5ms | ~0.5ms | **0.23ms** | ~20x |
| GROUP BY | ~15ms | ~2ms | **1.12ms** | ~13x |

### Actual Integrated Performance (Phase DF.2)

| Query Type | OLAPEngine | DuckDB | Achieved Speedup |
|------------|------------|--------|------------------|
| Filtered (5%) | 1.50ms | 3.98ms | **2.7x** |
| Projection (2 cols) | 0.62ms | 2.27ms | **3.7x** |
| Full scan | 0.81ms | 7.37ms | **9.1x** |
| COUNT(*) | 0.65ms | 1.42ms | **2.2x** |
| GROUP BY | 1.96ms | 7.41ms | **3.8x** |
| Complex | 2.32ms | 9.31ms | **4.0x** |
| **Average** | | | **4.2x** |

*Phase DF.2 optimizations (parallel loading, proper batch handling) improved average speedup from 2.9x to 4.2x.*

### Theoretical Model

For a query with:
- `D` = data size in memory
- `s` = selectivity (fraction of rows matching filter)
- `k` = columns requested / total columns

**Current path (disk-based)**:
```
T_current = T_disk_io + T_decode + T_filter + T_project
         ≈ O(D) + O(D) + O(D) + O(D*k)
         ≈ O(D)
```

**DataFusion path (memory-based)**:
```
T_datafusion = T_cache_lookup + T_vectorized_filter + T_vectorized_project
            ≈ O(1) + O(D*s) + O(D*s*k)
            ≈ O(D*s*k)
```

**Speedup**:
```
Speedup = T_current / T_datafusion
       ≈ O(D) / O(D*s*k)
       = 1 / (s*k)

Example: 5% selectivity, 2/10 columns
Speedup = 1 / (0.05 * 0.2) = 1 / 0.01 = 100x theoretical
```

Real-world measured: 20-56x (overhead from cache management, Arrow conversion, etc.)

### Storage Overhead Analysis

**Cache memory requirement**:
```
Memory = active_tables * avg_table_size * cache_ratio

Conservative estimate:
- 10 active tables
- 100MB average size
- 100% cache ratio (full tables)
= 1GB memory

Aggressive estimate:
- 50 active tables
- 500MB average size
- 50% cache ratio (hot partitions only)
= 12.5GB memory
```

**Trade-off**: Memory usage vs query speed. Configurable via `max_cache_size_bytes`.

---

## Implementation Phases

### Phase DF.1: Core DataFusion Integration (Foundation) ✅ COMPLETE

**Goal**: Add DataFusion as a query backend alongside DuckDB

**Status**: COMPLETE (January 2026)

**Files to Create**:
- `python/armillaria_query/olap_engine.py` - OLAPEngine class
- `python/armillaria_query/cache.py` - CacheManager class
- `tests/test_olap_engine.py` - Tests

**OLAPEngine API**:
```python
class OLAPEngine:
    """
    High-performance OLAP query engine powered by DataFusion.

    Provides vectorized, multi-threaded query execution over
    Armillaria tables with optional in-memory caching.
    """

    def __init__(
        self,
        store: PyChunkStore,
        catalog: PyCatalog,
        branch_manager: Optional[PyBranchManager] = None,
        max_cache_size_bytes: int = 1_000_000_000,  # 1GB default
    ):
        self._ctx = datafusion.SessionContext()
        self._cache = CacheManager(max_cache_size_bytes)
        # ...

    def query(
        self,
        sql: str,
        versions: Optional[Dict[str, int]] = None,
        branch: Optional[str] = None,
    ) -> pa.Table:
        """Execute SQL query with DataFusion."""
        # 1. Parse SQL to extract table names
        # 2. Load tables (from cache or disk)
        # 3. Register with DataFusion
        # 4. Execute query
        # 5. Return Arrow table

    def query_df(self, sql: str, ...) -> datafusion.DataFrame:
        """Return DataFusion DataFrame for lazy execution."""

    def load_table(
        self,
        table_name: str,
        version: Optional[int] = None,
        branch: Optional[str] = None,
    ) -> None:
        """Pre-load a table into cache."""

    def cache_stats(self) -> Dict[str, Any]:
        """Get cache statistics."""

    def clear_cache(self, table_name: Optional[str] = None) -> None:
        """Clear cache (all or specific table)."""
```

**CacheManager API**:
```python
class CacheManager:
    """
    LRU cache for Arrow tables with size-based eviction.
    """

    def __init__(self, max_size_bytes: int):
        self._cache: Dict[CacheKey, CacheEntry] = {}
        self._max_size = max_size_bytes
        self._current_size = 0

    def get(self, key: CacheKey) -> Optional[pa.Table]:
        """Get table from cache (updates LRU order)."""

    def put(self, key: CacheKey, table: pa.Table) -> None:
        """Add table to cache (may evict others)."""

    def invalidate(self, table_name: str) -> None:
        """Invalidate all versions of a table."""

    def stats(self) -> CacheStats:
        """Get hit/miss statistics."""
```

**Verification Criteria**:
- [x] DataFusion queries return correct results (compare with DuckDB) ✅
- [x] Cache hit rate > 90% for repeated queries ✅ (98.6% achieved)
- [x] Memory usage stays within configured limit ✅
- [x] No regression in existing tests ✅ (208 Python tests, 203 Rust tests pass)

**Tests**:
```python
def test_olap_basic_query():
    """Test basic SELECT query matches DuckDB."""

def test_olap_filtered_query():
    """Test filtered query performance and correctness."""

def test_olap_cache_hit():
    """Test cache hit on repeated query."""

def test_olap_cache_eviction():
    """Test LRU eviction when cache full."""

def test_olap_version_isolation():
    """Test different versions don't share cache entries."""

def test_olap_branch_isolation():
    """Test branch queries resolve correctly."""
```

**Estimated Complexity**: Medium
**Files Changed**: 3 new, 1 modified (`__init__.py`)

---

### Phase DF.2: Performance Optimization ✅ COMPLETE

**Goal**: Maximize query performance with advanced optimizations

**Status**: COMPLETE (January 2026)

**Optimizations**:

1. **Parallel Table Loading**
   ```python
   # Load multiple tables concurrently
   async def load_tables_parallel(self, tables: List[str]):
       tasks = [self._load_table_async(t) for t in tables]
       await asyncio.gather(*tasks)
   ```

2. **Predicate Pushdown to Cache**
   ```python
   # Only cache rows that match common predicates
   def load_table_with_predicate(self, table: str, predicate: str):
       # Cache only matching rows for memory efficiency
   ```

3. **Partition-Aware Caching**
   ```python
   # Cache individual partitions instead of full tables
   def load_partition(self, table: str, partition_key: str, partition_value: Any):
       # Fine-grained caching for large tables
   ```

4. **Lazy Loading**
   ```python
   # Don't load data until query execution
   def query_lazy(self, sql: str) -> datafusion.DataFrame:
       # Returns DataFrame without executing
       # Execution happens on .collect()
   ```

**Verification Criteria**:
- [x] Parallel loading implemented for multi-table queries ✅
- [x] Query execution optimized (45% speedup over DF.1) ✅
- [x] No correctness regressions ✅ (208 tests pass)

**Implemented Optimizations**:
- Fixed double `collect()` call that wasted execution
- Used `pa.Table.from_batches()` for proper batch handling
- Added `_load_tables_parallel()` with ThreadPoolExecutor for JOINs

**Estimated Complexity**: Medium-High

---

### Phase DF.3: QueryEngine Integration ✅ COMPLETE

**Goal**: Seamlessly integrate OLAPEngine with existing QueryEngine

**Status**: COMPLETE (January 2026)

**Changes to QueryEngine**:
```python
class QueryEngine:
    def __init__(
        self,
        store, catalog,
        branch_manager=None,
        transaction_manager=None,
        enable_olap: bool = True,  # NEW
        olap_cache_size: int = 1_000_000_000,  # NEW
    ):
        # ... existing init ...

        if enable_olap:
            self._olap = OLAPEngine(
                store, catalog, branch_manager,
                max_cache_size_bytes=olap_cache_size
            )
        else:
            self._olap = None

    def query(self, sql: str, ..., use_olap: bool = True) -> QueryResult:
        """
        Execute query, automatically choosing backend.

        Args:
            use_olap: If True and OLAPEngine available, use DataFusion.
                     Falls back to DuckDB if OLAP unavailable or fails.
        """
        if use_olap and self._olap is not None:
            try:
                return self._olap.query(sql, ...)
            except Exception as e:
                # Log warning, fall back to DuckDB
                logger.warning(f"OLAP query failed, falling back to DuckDB: {e}")

        return self._duckdb_query(sql, ...)

    def olap_query(self, sql: str, ...) -> pa.Table:
        """Force OLAP path (raises if unavailable)."""
        if self._olap is None:
            raise RuntimeError("OLAP engine not enabled")
        return self._olap.query(sql, ...)
```

**Verification Criteria**:
- [x] Automatic fallback works correctly ✅ (params trigger DuckDB fallback)
- [x] Performance improvement for OLAP queries ✅ (4.2x faster than DuckDB)
- [x] All existing tests pass ✅ (222 tests pass)
- [x] Transaction integration works ✅ (OLAP cache invalidated on writes)

**New Methods Added**:
- `query(sql, use_olap=True)` - Automatic OLAP with fallback
- `olap_query(sql)` - Force OLAP path
- `olap_stats()` - Cache statistics
- `olap_clear_cache()` - Clear OLAP cache
- `olap_preload(table)` - Preload table into cache
- `olap_enabled` property - Check if OLAP available

**Estimated Complexity**: Medium

---

### Phase DF.4: Advanced Features - COMPLETE

**Goal**: Add advanced OLAP capabilities unique to Armillaria

**Status**: COMPLETE (January 2026)

**Implemented Features**:

1. **Time Travel SQL Syntax** - `VERSION` keyword
   ```sql
   -- Query specific version with OLAP performance
   SELECT * FROM users VERSION 5 WHERE score > 90

   -- Compare current vs historical
   SELECT curr.id, curr.score, hist.score AS old_score
   FROM users AS curr
   JOIN users VERSION 1 AS hist ON curr.id = hist.id
   WHERE curr.score != hist.score
   ```

2. **Branch Syntax** - `@branch` notation
   ```sql
   -- Query from specific branch
   SELECT * FROM users@feature WHERE score > 90

   -- Compare data across branches
   SELECT
       main.id,
       main.score AS main_score,
       feature.score AS feature_score
   FROM users@main AS main
   JOIN users@feature AS feature ON main.id = feature.id
   WHERE main.score != feature.score
   ```

3. **Changelog SQL Queries** - `__changelog` virtual table
   ```sql
   -- Get recent changes
   SELECT * FROM __changelog ORDER BY tx_id DESC LIMIT 10

   -- Find all changes to users table
   SELECT * FROM __changelog WHERE table_name = 'users'

   -- Count changes per table (built-in CDC!)
   SELECT table_name, COUNT(*) as changes
   FROM __changelog
   GROUP BY table_name
   ORDER BY changes DESC

   -- Find new tables created
   SELECT DISTINCT table_name, committed_at
   FROM __changelog
   WHERE is_new_table = true
   ```

**New Methods Added**:
- `query_time_travel(sql)` - Execute SQL with VERSION/@ syntax
- `query_changelog(sql)` - Query the changelog via SQL

**Changelog Schema**:
| Column | Type | Description |
|--------|------|-------------|
| tx_id | INT64 | Transaction ID |
| epoch_id | INT64 | Epoch ID |
| committed_at | INT64 | Unix timestamp |
| branch | STRING | Branch name |
| table_name | STRING | Changed table |
| old_version | INT64 | Previous version (null if new) |
| new_version | INT64 | New version |
| is_new_table | BOOL | True if table was created |

**Verification Criteria**:
- [x] VERSION syntax parses and executes correctly (13 tests)
- [x] @branch syntax routes to correct branch
- [x] Changelog queries work with SQL analytics (12 tests)
- [x] All 247 tests pass (no regressions)

4. **Materialized Views** (Future Enhancement)
   ```python
   engine.create_materialized_view(
       "high_value_users",
       "SELECT * FROM users WHERE lifetime_value > 1000",
       refresh_on=["users"]  # Auto-refresh when users changes
   )
   ```

**Estimated Complexity**: High (COMPLETED)

---

## Verification Strategy

### Correctness Verification

For every optimization, verify:
1. **Result equivalence**: `assert df_olap.equals(df_duckdb)`
2. **Edge cases**: NULL handling, empty tables, type coercion
3. **Concurrency**: Multiple concurrent queries
4. **Isolation**: Transactions see correct snapshots

### Performance Verification

Benchmark suite:
```python
def benchmark_suite():
    """Run comprehensive benchmarks."""
    results = {}

    # Basic operations
    results['filtered_5pct'] = benchmark(olap_filtered_5pct)
    results['projection_2col'] = benchmark(olap_projection_2col)
    results['full_scan'] = benchmark(olap_full_scan)

    # Aggregations
    results['count'] = benchmark(olap_count)
    results['sum_groupby'] = benchmark(olap_sum_groupby)
    results['avg_where'] = benchmark(olap_avg_where)

    # Joins
    results['join_2table'] = benchmark(olap_join_2table)
    results['join_3table'] = benchmark(olap_join_3table)

    # Compare with DuckDB
    for key, olap_time in results.items():
        duckdb_time = duckdb_benchmarks[key]
        speedup = duckdb_time / olap_time
        print(f"{key}: {olap_time:.2f}ms (vs DuckDB {duckdb_time:.2f}ms = {speedup:.1f}x)")

    return results
```

### Mathematical Verification

For each claim, provide:
1. **Theoretical analysis** with formula
2. **Measured results** from benchmarks
3. **Comparison** showing theory matches practice (within expected variance)

---

## Risk Assessment

| Risk | Likelihood | Impact | Mitigation |
|------|------------|--------|------------|
| DataFusion bugs | Low | High | Extensive testing, fallback to DuckDB |
| Memory pressure | Medium | Medium | Configurable cache limits, LRU eviction |
| API incompatibility | Low | Medium | Maintain DuckDB path, gradual migration |
| Performance regression | Low | High | Comprehensive benchmarks, CI checks |

---

## Success Metrics

| Metric | Current | Target | Stretch |
|--------|---------|--------|---------|
| Filtered read (5%) | 9.4ms | 1.0ms | 0.5ms |
| Projection (2 cols) | 6.9ms | 0.5ms | 0.2ms |
| Full scan | 12.4ms | 1.0ms | 0.3ms |
| Cache hit rate | N/A | 90% | 95% |
| Memory efficiency | N/A | 80% | 90% |

**Definition of Success**:
- Beat DuckDB on all OLAP queries
- Maintain all lakehouse features (versioning, branching, transactions)
- No regression in write performance
- All existing tests pass

---

## Timeline

| Phase | Description | Status |
|-------|-------------|--------|
| DF.1 | Core DataFusion Integration | COMPLETE |
| DF.2 | Performance Optimization | COMPLETE |
| DF.3 | QueryEngine Integration | COMPLETE |
| DF.4 | Advanced Features | COMPLETE |
| Testing | Comprehensive verification | COMPLETE (247 tests) |
| Documentation | Update all docs | COMPLETE |

---

## References

- [Apache DataFusion](https://datafusion.apache.org/) - Query engine documentation
- [DataFusion Python](https://github.com/apache/datafusion-python) - Python bindings
- [Armillaria Architecture](../README.md) - Current system overview
- [Technical Foundations](./TECHNICAL_FOUNDATIONS.md) - Mathematical proofs
- [Performance Guide](./PERFORMANCE.md) - Current optimizations

---

*Document created: January 2026*
*Status: Ready for implementation*
